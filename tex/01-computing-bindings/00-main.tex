\section{Computing Co-occurence Embeddings}
In this part of the assignment you will implement a co-occurrence based word embedding model. We will be using the Reuters (business and financial news) corpus. This corpus consists of 10,788 news documents totaling 1.3 million words. These documents span 90 categories and are split into train and test sets. For more details, please see \url{https://www.nltk.org/book/ch02.html}. \newline

The following problem involves coding. In this class, assignment code files will be shared via a GitHub Team named \textit{XCS224N Students}. To get started, you'll need to make a copy of the XCS224N-A1 repo that has been added to the Team. \textbf{If you have not yet joined the GitHub Team, follow the instructions "Joining GitHub" on Page 3 of your XCS224N Course Syllabus.}

\begin{enumerate}[(a)]
    % Question 1-A
    \item \points{1a} Implement the \texttt{distinct\_words} function in \texttt{co\_occurrence.py}. You can do this with for loops, but it's more efficient to do it with Python list comprehensions.
    
    \item \points{1b} Implement the \texttt{compute\_co\_occurrence} function in \texttt{co\_occurrence.py}. If you aren't familiar with the python \texttt{numpy} package, we suggest walking yourself through this tutorial: \url{http://cs231n.github.io/python-numpy-tutorial}. 
    
    \item \points{1c} Implement the \texttt{reduce\_to\_k\_dim} function in \texttt{co\_occurrence.py}. \newline
    
    \textbf{Note}: All of numpy, scipy, and scikit-learn (sklearn) provide some implementation of SVD, but only scipy and sklearn provide an implementation of Truncated SVD, and only sklearn provides an efficient randomized algorithm for calculating large-scale Truncated SVD. Please use sklearn.decomposition.TruncatedSVD.
    
    
    \item (0 points) Show time! Now we are going to load the Reuters corpus and compute some word vectors with everything you just implemented! There is no additional code to write for this part; just run \texttt{python run.py}. This will generate a plot of the embeddings for hand-picked words which have been dimensionally reduced to 2-dimensions. Try and take note of some of the clusters and patterns you do or don't see. Think about what you can and can't make sense of. \textbf{The plot will be referenced in Question 1 of the multiple choice question set in Part 2 below}. 
\end{enumerate}

Once finished with this part of your assignment, run the \texttt{collect\_submission.sh} script to produce your \texttt{assignment1.zip} file. If you have trouble with the shell script, check the \texttt{README.md} file in the GitHub repo for the list of files you'll need to submit. Then upload your \texttt{assignment1.zip} file or the individual files via the Gradescope submission link in the Assignment 1 block of your SCPD learning portal. The submission link is titled \textbf{Assignment 1 Coding Submission Link}.